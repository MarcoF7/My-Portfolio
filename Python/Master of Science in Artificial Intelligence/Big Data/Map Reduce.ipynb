{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rvr7P31HkKk"
   },
   "source": [
    "<center><img src='https://netacad.centralesupelec.fr/img/cs.jpg' width=200></center>\n",
    "\n",
    "<h6><center><b>Big data algorithms, techniques and platforms</b></center></h6>\n",
    "\n",
    "<h1>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "<center>MapReduce programming in Python</center>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "</h1>\n",
    "\n",
    "\n",
    "MapReduce programming in Python.\n",
    "\n",
    "* You'll use **Python** as a programming language.\n",
    "\n",
    "* You'll use the library **mrjob** that lets you write MapReduce jobs in Python.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "In order to install **mrjob**, execute the following cell.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4667,
     "status": "ok",
     "timestamp": 1610264874050,
     "user": {
      "displayName": "MARCO ANTONIO FARFAN QUIROZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyouCic8PRJa_OhiXqrKl9D6yotjSxiwR5iKw9=s64",
      "userId": "01920866730777537430"
     },
     "user_tz": -60
    },
    "id": "Mqo0AOwNHaaH",
    "outputId": "d0fcd780-04aa-42b6-b8af-a2eb8641440d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mrjob\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/58/fc28ab743aba16e90736ad4e29694bd2adaf7b879376ff149306d50c4e90/mrjob-0.7.4-py2.py3-none-any.whl (439kB)\n",
      "\r",
      "\u001b[K     |▊                               | 10kB 14.2MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 20kB 15.3MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 30kB 9.0MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 40kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 51kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 61kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 71kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 81kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 92kB 5.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 102kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 112kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 122kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 133kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 143kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 153kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 163kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 174kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 184kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 194kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 204kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 215kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 225kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 235kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 245kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 256kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 266kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 276kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 286kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 296kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 307kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 317kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 327kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 337kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 348kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 358kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 368kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 378kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 389kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 399kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 409kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 419kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 430kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 440kB 5.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from mrjob) (3.13)\n",
      "Installing collected packages: mrjob\n",
      "Successfully installed mrjob-0.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install mrjob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnbafZ_bI1rE"
   },
   "source": [
    "## How to use *mrjob*\n",
    "\n",
    "In this section, we show an example of how to use *mrjob* to implement MapReduce jobs.\n",
    "For this purpose, we implement a MapReduce job to count the number of occurrences of each word in a text document.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Read the code and the comments** in the following cell to understand how to write a MapReduce job in *mrjob*\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1610264876482,
     "user": {
      "displayName": "MARCO ANTONIO FARFAN QUIROZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyouCic8PRJa_OhiXqrKl9D6yotjSxiwR5iKw9=s64",
      "userId": "01920866730777537430"
     },
     "user_tz": -60
    },
    "id": "EzMfV-w7IZwM",
    "outputId": "5d8867fb-80c8-4be3-c63e-3900dc3f1731"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing wordcount.py\n"
     ]
    }
   ],
   "source": [
    "# The following declaration \n",
    "# triggers the creation of a file named wordcount.py after the execution \n",
    "# of this cell.\n",
    "%%file wordcount.py\n",
    "\n",
    "# We import the class MRJob from the library.\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "# We define a custom class that represents our \n",
    "# specific MapReduce job. \n",
    "# This class inherits from MRJob.\n",
    "class WordCount(MRJob):\n",
    "\n",
    "    # We define the map function (here called mapper).\n",
    "    def mapper(self, _, line): \n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        self : this object \n",
    "          (just ignore it if you're not familiar with object-oriented languages)\n",
    "\n",
    "        key: Map takes in a (key, value) pair. We don't use here the key (hence we have _).\n",
    "\n",
    "        line: A line of the input file.\n",
    "        '''\n",
    "\n",
    "        # We loop over a line in the input file.\n",
    "        for word in line.split():\n",
    "            # For each word in line, we output (word, 1)\n",
    "            # yield = return, with the only difference that it does not stop the for loop\n",
    "            yield(word, 1)\n",
    "\n",
    "    # We define the combine function, here called combiner.\n",
    "    def combiner(self, word, values):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "         self: this object\n",
    "         word: a word (the key)\n",
    "         values: The list of values associated with the key (here [1, ...., 1])\n",
    "\n",
    "        '''\n",
    "        # Technically, values is an iterator.\n",
    "        # We convert it into a list. This is useful if we want to iterate \n",
    "        # over the list many times.\n",
    "        l = list(values)\n",
    "\n",
    "        # We return (word, sum over the values)\n",
    "        yield(word, sum(l))\n",
    "  \n",
    "    # We define the reduce function, here called reducer\n",
    "    def reducer(self, word, counts):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "          self: this object.\n",
    "          word: the key.\n",
    "          counts: the list of the counts associated with the key.\n",
    "        '''\n",
    "        l = list(counts)\n",
    "        yield(word, sum(l))\n",
    "\n",
    "# The entry point of the program.\n",
    "if __name__ == '__main__': \n",
    "    # Start the MapReduce job.\n",
    "    WordCount.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXb9RvVaSuwT"
   },
   "source": [
    "We create a toy text file in order to try our implementation.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "**Execute the following cell** to create file test.txt\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1610264878774,
     "user": {
      "displayName": "MARCO ANTONIO FARFAN QUIROZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyouCic8PRJa_OhiXqrKl9D6yotjSxiwR5iKw9=s64",
      "userId": "01920866730777537430"
     },
     "user_tz": -60
    },
    "id": "P3BSWULwS4Mr",
    "outputId": "0b2a6810-38e5-417d-fd1e-1b351fd8d1c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test.txt\n"
     ]
    }
   ],
   "source": [
    "%%file test.txt\n",
    "CentraleSupélec (CS) is a prestigious French institute of \n",
    "research and higher education in engineering and science \n",
    "and a graduate school of Paris-Saclay University. \n",
    "It is a key founding member of the Paris-Saclay University, \n",
    "the TIME (Top Industrial Managers for Europe) network \n",
    "and also the CESAER association of European engineering schools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6XKLnhASk3o"
   },
   "source": [
    "\n",
    "---\n",
    "**Execute the following cell** to run the MapReduce job on the file *test.txt*\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3336,
     "status": "ok",
     "timestamp": 1610264883672,
     "user": {
      "displayName": "MARCO ANTONIO FARFAN QUIROZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyouCic8PRJa_OhiXqrKl9D6yotjSxiwR5iKw9=s64",
      "userId": "01920866730777537430"
     },
     "user_tz": -60
    },
    "id": "kHko74t5SjbE",
    "outputId": "d447cfec-ce55-4fbe-d02f-1a8a48963d6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for local runner\n",
      "Creating temp directory /tmp/wordcount.root.20210110.074759.230026\n",
      "Running step 1 of 1...\n",
      "job output is in /tmp/wordcount.root.20210110.074759.230026/output\n",
      "Streaming final output from /tmp/wordcount.root.20210110.074759.230026/output...\n",
      "\"network\"\t1\n",
      "\"of\"\t4\n",
      "\"prestigious\"\t1\n",
      "\"research\"\t1\n",
      "\"school\"\t1\n",
      "\"schools.\"\t1\n",
      "\"science\"\t1\n",
      "\"the\"\t3\n",
      "\"(CS)\"\t1\n",
      "\"(Top\"\t1\n",
      "\"CESAER\"\t1\n",
      "\"CentraleSup\\u00e9lec\"\t1\n",
      "\"Europe)\"\t1\n",
      "\"European\"\t1\n",
      "\"French\"\t1\n",
      "\"Industrial\"\t1\n",
      "\"It\"\t1\n",
      "\"Managers\"\t1\n",
      "\"Paris-Saclay\"\t2\n",
      "\"TIME\"\t1\n",
      "\"University,\"\t1\n",
      "\"University.\"\t1\n",
      "\"a\"\t3\n",
      "\"also\"\t1\n",
      "\"and\"\t4\n",
      "\"association\"\t1\n",
      "\"education\"\t1\n",
      "\"engineering\"\t2\n",
      "\"for\"\t1\n",
      "\"founding\"\t1\n",
      "\"graduate\"\t1\n",
      "\"higher\"\t1\n",
      "\"in\"\t1\n",
      "\"institute\"\t1\n",
      "\"is\"\t2\n",
      "\"key\"\t1\n",
      "\"member\"\t1\n",
      "Removing temp directory /tmp/wordcount.root.20210110.074759.230026...\n"
     ]
    }
   ],
   "source": [
    "!python wordcount.py -r local test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NydL-w1bPqOW"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "With this example you have all the ingredients to implement your own MapReduce jobs.\n",
    "\n",
    "For more information and examples you can [look at the documentation.](https://mrjob.readthedocs.io/en/latest/guides/writing-mrjobs.html)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahKZPS2eUFFg"
   },
   "source": [
    "## Exercise 1: Counting even and odd numbers\n",
    "\n",
    "The following file *numbers.txt* is given, where each line contains a list of integer numbers.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "Execute the cell in order to create the file *numbers.txt*\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1610264890763,
     "user": {
      "displayName": "MARCO ANTONIO FARFAN QUIROZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyouCic8PRJa_OhiXqrKl9D6yotjSxiwR5iKw9=s64",
      "userId": "01920866730777537430"
     },
     "user_tz": -60
    },
    "id": "894ueZL51szk",
    "outputId": "b900bc91-b0d5-4744-ce4e-970752abc30c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing numbers.txt\n"
     ]
    }
   ],
   "source": [
    "%%file numbers.txt\n",
    "1 2 3 3\n",
    "3 4 4\n",
    "5 6 7\n",
    "9 8 7 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xifb8lF6QeSP"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Implement a MapReduce job that counts the number of even and odd numbers in the file.**\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1610264916615,
     "user": {
      "displayName": "MARCO ANTONIO FARFAN QUIROZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyouCic8PRJa_OhiXqrKl9D6yotjSxiwR5iKw9=s64",
      "userId": "01920866730777537430"
     },
     "user_tz": -60
    },
    "id": "mRsKquLYIecD",
    "outputId": "0017f1b9-947f-4d42-a105-6f765f8cb822"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing oddeven.py\n"
     ]
    }
   ],
   "source": [
    "%%file oddeven.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class OddEven(MRJob):\n",
    "    def mapper(self, _, line): \n",
    "        for num in line.split():\n",
    "            if int(num) % 2 == 0:\n",
    "                yield(\"even\", 1)\n",
    "            else:\n",
    "                yield(\"odd\", 1)\n",
    "  \n",
    "    def reducer(self, type, counts):\n",
    "        yield(type, sum(counts))\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    OddEven.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_RB1XoC1m3P"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "**Execute the following cell to test your implementation.**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2371,
     "status": "ok",
     "timestamp": 1610264921735,
     "user": {
      "displayName": "MARCO ANTONIO FARFAN QUIROZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyouCic8PRJa_OhiXqrKl9D6yotjSxiwR5iKw9=s64",
      "userId": "01920866730777537430"
     },
     "user_tz": -60
    },
    "id": "Hn9QPxLYVXI6",
    "outputId": "e4671714-b398-4ce3-9827-37dadda93c86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for local runner\n",
      "Creating temp directory /tmp/oddeven.root.20210110.074838.251520\n",
      "Running step 1 of 1...\n",
      "job output is in /tmp/oddeven.root.20210110.074838.251520/output\n",
      "Streaming final output from /tmp/oddeven.root.20210110.074838.251520/output...\n",
      "\"even\"\t6\n",
      "\"odd\"\t8\n",
      "Removing temp directory /tmp/oddeven.root.20210110.074838.251520...\n"
     ]
    }
   ],
   "source": [
    "!python oddeven.py -r local numbers.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnI5VcLHRW_l"
   },
   "source": [
    "## Exercise 2 -- Computing the average\n",
    "\n",
    "The following file *temperatures.txt* is given, where each line gives an average monthly temperature. Two years are recorded (1980 and 1981).\n",
    "\n",
    "\n",
    "---\n",
    "**Execute the following cell to create the file**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1610264929387,
     "user": {
      "displayName": "MARCO ANTONIO FARFAN QUIROZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyouCic8PRJa_OhiXqrKl9D6yotjSxiwR5iKw9=s64",
      "userId": "01920866730777537430"
     },
     "user_tz": -60
    },
    "id": "5hwLfmVnSUY0",
    "outputId": "8940f3be-6dd4-47f0-f2a6-58f7c47055a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temperatures.txt\n"
     ]
    }
   ],
   "source": [
    "%%file temperatures.txt\n",
    "1980,1,5\n",
    "1980,2,2\n",
    "1980,3,10\n",
    "1980,4,14\n",
    "1980,5,17\n",
    "1980,6,22\n",
    "1980,7,28\n",
    "1980,8,30\n",
    "1980,9,21\n",
    "1980,10,15\n",
    "1980,11,4\n",
    "1980,12,1\n",
    "1981,1,2\n",
    "1981,2,1\n",
    "1981,3,-3\n",
    "1981,4,3\n",
    "1981,5,10\n",
    "1981,6,26\n",
    "1981,7,20\n",
    "1981,8,22\n",
    "1981,9,28\n",
    "1981,10,4\n",
    "1981,11,-2\n",
    "1981,12,-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7S7J39vxTkq4"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "**Implement a MapReduce job to get the average monthly temperature for each year.**\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 574,
     "status": "ok",
     "timestamp": 1610264933177,
     "user": {
      "displayName": "MARCO ANTONIO FARFAN QUIROZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyouCic8PRJa_OhiXqrKl9D6yotjSxiwR5iKw9=s64",
      "userId": "01920866730777537430"
     },
     "user_tz": -60
    },
    "id": "XGXRLN1JTysj",
    "outputId": "5b0393e4-2859-4534-bb4c-35c2af5c7201"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temperatures.py\n"
     ]
    }
   ],
   "source": [
    "%%file temperatures.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class AvgTemperatures(MRJob):\n",
    "    def mapper(self, _, line): \n",
    "        value = line.split(\",\")\n",
    "        yield (value[0], float(value[2]))\n",
    "  \n",
    "    def combiner(self, year, temps):\n",
    "        temps_l = list(temps)\n",
    "        yield (year, (sum(temps_l), len(temps_l)) )\n",
    "\n",
    "    def reducer(self, year, values):\n",
    "        s = 0\n",
    "        l = 0\n",
    "        for v in values:\n",
    "            s += v[0]\n",
    "            l += v[1]\n",
    "        yield (year, s/l)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__': \n",
    "    AvgTemperatures.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgLXCMmIUACl"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "**Execute the following cell to test your implementation.**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3329,
     "status": "ok",
     "timestamp": 1610264937922,
     "user": {
      "displayName": "MARCO ANTONIO FARFAN QUIROZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyouCic8PRJa_OhiXqrKl9D6yotjSxiwR5iKw9=s64",
      "userId": "01920866730777537430"
     },
     "user_tz": -60
    },
    "id": "LBD2B2iPUIGC",
    "outputId": "b7b1290d-0a95-4610-e86b-bf20bcadc29f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for local runner\n",
      "Creating temp directory /tmp/temperatures.root.20210110.074853.482298\n",
      "Running step 1 of 1...\n",
      "job output is in /tmp/temperatures.root.20210110.074853.482298/output\n",
      "Streaming final output from /tmp/temperatures.root.20210110.074853.482298/output...\n",
      "\"1980\"\t14.083333333333334\n",
      "\"1981\"\t8.916666666666666\n",
      "Removing temp directory /tmp/temperatures.root.20210110.074853.482298...\n"
     ]
    }
   ],
   "source": [
    "!python temperatures.py -r local temperatures.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b3xIxUUV-Gq"
   },
   "source": [
    "## Exercise 3 - Inverted index\n",
    "\n",
    "Suppose that we have a list of documents (e.g., books);\n",
    "we want to create an **inverted index** that associates each word to the list of the documents the word occurs in.\n",
    "\n",
    "As an input file, we use the file *books.json*. \n",
    "Each line of this file is a key-value pair, where the key is the name of a file (title of a book) and the value is the content of that file. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Execute the following cell to create the file books.json**\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 547,
     "status": "ok",
     "timestamp": 1610265777002,
     "user": {
      "displayName": "MARCO ANTONIO FARFAN QUIROZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyouCic8PRJa_OhiXqrKl9D6yotjSxiwR5iKw9=s64",
      "userId": "01920866730777537430"
     },
     "user_tz": -60
    },
    "id": "EgB6xhSc2IRv",
    "outputId": "66b627cc-c8a9-4bff-cab0-dfa4fdf98d14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing books.json\n"
     ]
    }
   ],
   "source": [
    "%%file books.json\n",
    "[\"milton-paradise.txt\", \"[ Paradise Lost by John Milton 1667 ] Book I Of Man ' s first disobedience , and the fruit Of that forbidden tree whose mortal taste Brought death into the World , and all our woe , With loss of Eden , till one greater Man Restore us , and regain the blissful seat , Sing , Heavenly Muse , that , on the secret top Of Oreb , or of Sinai , didst inspire That shepherd who first taught the chosen seed In the beginning how the heavens and earth Rose out of Chaos : or , if Sion hill Delight thee more , and Siloa ' s brook that flowed Fast by the oracle of God , I thence Invoke thy aid to my adventurous song , That with no middle flight intends to soar Above th ' Aonian mount , while it pursues Things unattempted yet in prose or rhyme .\"]\n",
    "[\"edgeworth-parents.txt\", \"[ The Parent ' s Assistant , by Maria Edgeworth ] THE ORPHANS . Near the ruins of the castle of Rossmore , in Ireland , is a small cabin , in which there once lived a widow and her four children . As long as she was able to work , she was very industrious , and was accounted the best spinner in the parish ; but she overworked herself at last , and fell ill , so that she could not sit to her wheel as she used to do , and was obliged to give it up to her eldest daughter , Mary .\"]\n",
    "[\"austen-emma.txt\", \"[ Emma by Jane Austen 1816 ] VOLUME I CHAPTER I Emma Woodhouse , handsome , clever , and rich , with a comfortable home and happy disposition , seemed to unite some of the best blessings of existence ; and had lived nearly twenty - one years in the world with very little to distress or vex her . She was the youngest of the two daughters of a most affectionate , indulgent father ; and had , in consequence of her sister ' s marriage , been mistress of his house from a very early period . Her mother had died too long ago for her to have more than an indistinct remembrance of her caresses ; and her place had been supplied by an excellent woman as governess , who had fallen little short of a mother in affection .\"]\n",
    "[\"chesterton-ball.txt\", \"[ The Ball and The Cross by G . K . Chesterton 1909 ] I . A DISCUSSION SOMEWHAT IN THE AIR The flying ship of Professor Lucifer sang through the skies like a silver arrow ; the bleak white steel of it , gleaming in the bleak blue emptiness of the evening . That it was far above the earth was no expression for it ; to the two men in it , it seemed to be far above the stars . The professor had himself invented the flying machine , and had also invented nearly everything in it .\"]\n",
    "[\"bible-kjv.txt\", \"[ The King James Bible ] The Old Testament of the King James Bible The First Book of Moses : Called Genesis 1 : 1 In the beginning God created the heaven and the earth . 1 : 2 And the earth was without form , and void ; and darkness was upon the face of the deep . And the Spirit of God moved upon the face of the waters . 1 : 3 And God said , Let there be light : and there was light . 1 : 4 And God saw the light , that it was good : and God divided the light from the darkness . 1 : 5 And God called the light Day , and the darkness he called Night . And the evening and the morning were the first day .\"]\n",
    "[\"chesterton-thursday.txt\", \"[ The Man Who Was Thursday by G . K . Chesterton 1908 ] To Edmund Clerihew Bentley A cloud was on the mind of men , and wailing went the weather , Yea , a sick cloud upon the soul when we were boys together . Science announced nonentity and art admired decay ; The world was old and ended : but you and I were gay ; Round us in antic order their crippled vices came -- Lust that had lost its laughter , fear that had lost its shame . Like the white lock of Whistler , that lit our aimless gloom , Men showed their own white feather as proudly as a plume . Life was a fly that faded , and death a drone that stung ; The world was very old indeed when you and I were young .\"]\n",
    "[\"blake-poems.txt\", \"[ Poems by William Blake 1789 ] SONGS OF INNOCENCE AND OF EXPERIENCE and THE BOOK of THEL SONGS OF INNOCENCE INTRODUCTION Piping down the valleys wild , Piping songs of pleasant glee , On a cloud I saw a child , And he laughing said to me : \\\" Pipe a song about a Lamb !\\\" So I piped with merry cheer . \\\" Piper , pipe that song again ;\\\" So I piped : he wept to hear . \\\" Drop thy pipe , thy happy pipe ; Sing thy songs of happy cheer :!\\\" So I sang the same again , While he wept with joy to hear . \\\" Piper , sit thee down and write In a book , that all may read .\\\" So he vanish ' d from my sight ; And I pluck ' d a hollow reed , And I made a rural pen , And I stain ' d the water clear , And I wrote my happy songs Every child may joy to hear .\"]\n",
    "[\"shakespeare-caesar.txt\", \"[ The Tragedie of Julius Caesar by William Shakespeare 1599 ] Actus Primus . Scoena Prima . Enter Flauius , Murellus , and certaine Commoners ouer the Stage . Flauius . Hence : home you idle Creatures , get you home : Is this a Holiday ? What , know you not ( Being Mechanicall ) you ought not walke Vpon a labouring day , without the signe Of your Profession ? Speake , what Trade art thou ? Car . Why Sir , a Carpenter Mur . Where is thy Leather Apron , and thy Rule ? What dost thou with thy best Apparrell on ? You sir , what Trade are you ? Cobl . Truely Sir , in respect of a fine Workman , I am but as you would say , a Cobler Mur . But what Trade art thou ? Answer me directly Cob . A Trade Sir , that I hope I may vse , with a safe Conscience , which is indeed Sir , a Mender of bad soules Fla .\"]\n",
    "[\"whitman-leaves.txt\", \"[ Leaves of Grass by Walt Whitman 1855 ] Come , said my soul , Such verses for my Body let us write , ( for we are one ,) That should I after return , Or , long , long hence , in other spheres , There to some group of mates the chants resuming , ( Tallying Earth ' s soil , trees , winds , tumultuous waves ,) Ever with pleas ' d smile I may keep on , Ever and ever yet the verses owning -- as , first , I here and now Signing for Soul and Body , set to them my name , Walt Whitman [ BOOK I . INSCRIPTIONS ] } One ' s - Self I Sing One ' s - self I sing , a simple separate person , Yet utter the word Democratic , the word En - Masse .\"]\n",
    "[\"melville-moby_dick.txt\", \"[ Moby Dick by Herman Melville 1851 ] ETYMOLOGY . ( Supplied by a Late Consumptive Usher to a Grammar School ) The pale Usher -- threadbare in coat , heart , body , and brain ; I see him now . He was ever dusting his old lexicons and grammars , with a queer handkerchief , mockingly embellished with all the gay flags of all the known nations of the world . He loved to dust his old grammars ; it somehow mildly reminded him of his mortality .\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rF1ZNgI2WNz"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Write a MapReduce job to create an inverted index.**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "**Hint.** Given a line in this file, you can use the instruction *json.loads(line)* to obtain a key-value pair, where the key is the name of a document (e.g., milton-paradise.txt) and the value is the content of the document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 554,
     "status": "ok",
     "timestamp": 1610265790187,
     "user": {
      "displayName": "MARCO ANTONIO FARFAN QUIROZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyouCic8PRJa_OhiXqrKl9D6yotjSxiwR5iKw9=s64",
      "userId": "01920866730777537430"
     },
     "user_tz": -60
    },
    "id": "9StmpyMUVs6X",
    "outputId": "dd69fed6-64a2-48b8-f0a5-6d547662f37a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing inverted_index.py\n"
     ]
    }
   ],
   "source": [
    "%%file inverted_index.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "import json\n",
    "\n",
    "import re\n",
    "\n",
    "regex = re.compile('[^a-zA-Z ]')\n",
    "stopwords = [\"i\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\"what\",\"which\",\"who\",\"whom\",\"this\",\"that\",\"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\"doing\",\"a\",\"an\",\"the\",\"and\",\"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\"about\",\"against\",\"between\",\"into\",\"through\",\"during\",\"before\",\"after\",\"above\",\"below\",\"to\",\"from\",\"up\",\"down\",\"in\",\"out\",\"on\",\"off\",\"over\",\"under\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\"any\",\"both\",\"each\",\"few\",\"more\",\"most\",\"other\",\"some\",\"such\",\"no\",\"nor\",\"not\",\"only\",\"own\",\"same\",\"so\",\"than\",\"too\",\"very\",\"s\",\"t\",\"can\",\"will\",\"just\",\"don\",\"should\",\"now\",\"like\",\"upon\",\"would\",\"through\",\"yet\",\"still\",\"thou\",\"may\",\"could\",\"never\",\"almost\",\"ever\",\"even\",\"might\",\"among\",\"without\",\"let\"]\n",
    "\n",
    "def preprocess(word):\n",
    "    word = regex.sub('', word)\n",
    "    if len(word) == 0:\n",
    "        return None\n",
    "    word = word.lower()\n",
    "    if word in stopwords:\n",
    "        return None\n",
    "    return word\n",
    "\n",
    "class InvertedIndex(MRJob):\n",
    "    def mapper(self, _, line): \n",
    "        record = json.loads(line)\n",
    "        for word in record[1].split():\n",
    "            word = preprocess(word)\n",
    "            if word is not None:\n",
    "                yield(word, record[0])\n",
    "  \n",
    "    def reducer(self, word, files):\n",
    "        files_nodup = list(set(files))\n",
    "        yield(word, files_nodup)\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    InvertedIndex.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQSCcjl2Vm7a"
   },
   "source": [
    "---\n",
    "**Execute the following cell to test your implementation.**\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2755,
     "status": "ok",
     "timestamp": 1610265794550,
     "user": {
      "displayName": "MARCO ANTONIO FARFAN QUIROZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyouCic8PRJa_OhiXqrKl9D6yotjSxiwR5iKw9=s64",
      "userId": "01920866730777537430"
     },
     "user_tz": -60
    },
    "id": "gsbvODXKrVUN",
    "outputId": "03e10de3-2cee-405e-ab3f-fa9df8c0bd7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for local runner\n",
      "Creating temp directory /tmp/inverted_index.root.20210110.080310.691190\n",
      "Running step 1 of 1...\n",
      "job output is in /tmp/inverted_index.root.20210110.080310.691190/output\n",
      "Streaming final output from /tmp/inverted_index.root.20210110.080310.691190/output...\n",
      "\"signing\"\t[\"whitman-leaves.txt\"]\n",
      "\"siloa\"\t[\"milton-paradise.txt\"]\n",
      "\"silver\"\t[\"chesterton-ball.txt\"]\n",
      "\"simple\"\t[\"whitman-leaves.txt\"]\n",
      "\"sinai\"\t[\"milton-paradise.txt\"]\n",
      "\"sing\"\t[\"whitman-leaves.txt\", \"milton-paradise.txt\", \"blake-poems.txt\"]\n",
      "\"sion\"\t[\"milton-paradise.txt\"]\n",
      "\"sir\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"sister\"\t[\"austen-emma.txt\"]\n",
      "\"sit\"\t[\"edgeworth-parents.txt\", \"blake-poems.txt\"]\n",
      "\"skies\"\t[\"chesterton-ball.txt\"]\n",
      "\"small\"\t[\"edgeworth-parents.txt\"]\n",
      "\"smile\"\t[\"whitman-leaves.txt\"]\n",
      "\"soar\"\t[\"milton-paradise.txt\"]\n",
      "\"soil\"\t[\"whitman-leaves.txt\"]\n",
      "\"somehow\"\t[\"melville-moby_dick.txt\"]\n",
      "\"somewhat\"\t[\"chesterton-ball.txt\"]\n",
      "\"song\"\t[\"milton-paradise.txt\", \"blake-poems.txt\"]\n",
      "\"songs\"\t[\"blake-poems.txt\"]\n",
      "\"soul\"\t[\"whitman-leaves.txt\", \"chesterton-thursday.txt\"]\n",
      "\"soules\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"speake\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"spheres\"\t[\"whitman-leaves.txt\"]\n",
      "\"spinner\"\t[\"edgeworth-parents.txt\"]\n",
      "\"spirit\"\t[\"bible-kjv.txt\"]\n",
      "\"stage\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"stain\"\t[\"blake-poems.txt\"]\n",
      "\"stars\"\t[\"chesterton-ball.txt\"]\n",
      "\"steel\"\t[\"chesterton-ball.txt\"]\n",
      "\"stung\"\t[\"chesterton-thursday.txt\"]\n",
      "\"supplied\"\t[\"austen-emma.txt\", \"melville-moby_dick.txt\"]\n",
      "\"tallying\"\t[\"whitman-leaves.txt\"]\n",
      "\"taste\"\t[\"milton-paradise.txt\"]\n",
      "\"taught\"\t[\"milton-paradise.txt\"]\n",
      "\"testament\"\t[\"bible-kjv.txt\"]\n",
      "\"th\"\t[\"milton-paradise.txt\"]\n",
      "\"thee\"\t[\"milton-paradise.txt\", \"blake-poems.txt\"]\n",
      "\"thel\"\t[\"blake-poems.txt\"]\n",
      "\"thence\"\t[\"milton-paradise.txt\"]\n",
      "\"things\"\t[\"milton-paradise.txt\"]\n",
      "\"threadbare\"\t[\"melville-moby_dick.txt\"]\n",
      "\"thursday\"\t[\"chesterton-thursday.txt\"]\n",
      "\"thy\"\t[\"milton-paradise.txt\", \"shakespeare-caesar.txt\", \"blake-poems.txt\"]\n",
      "\"till\"\t[\"milton-paradise.txt\"]\n",
      "\"together\"\t[\"chesterton-thursday.txt\"]\n",
      "\"top\"\t[\"milton-paradise.txt\"]\n",
      "\"trade\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"tragedie\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"tree\"\t[\"milton-paradise.txt\"]\n",
      "\"trees\"\t[\"whitman-leaves.txt\"]\n",
      "\"truely\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"tumultuous\"\t[\"whitman-leaves.txt\"]\n",
      "\"twenty\"\t[\"austen-emma.txt\"]\n",
      "\"two\"\t[\"austen-emma.txt\", \"chesterton-ball.txt\"]\n",
      "\"unattempted\"\t[\"milton-paradise.txt\"]\n",
      "\"unite\"\t[\"austen-emma.txt\"]\n",
      "\"us\"\t[\"whitman-leaves.txt\", \"chesterton-thursday.txt\", \"milton-paradise.txt\"]\n",
      "\"used\"\t[\"edgeworth-parents.txt\"]\n",
      "\"usher\"\t[\"melville-moby_dick.txt\"]\n",
      "\"utter\"\t[\"whitman-leaves.txt\"]\n",
      "\"valleys\"\t[\"blake-poems.txt\"]\n",
      "\"vanish\"\t[\"blake-poems.txt\"]\n",
      "\"verses\"\t[\"whitman-leaves.txt\"]\n",
      "\"vex\"\t[\"austen-emma.txt\"]\n",
      "\"vices\"\t[\"chesterton-thursday.txt\"]\n",
      "\"void\"\t[\"bible-kjv.txt\"]\n",
      "\"volume\"\t[\"austen-emma.txt\"]\n",
      "\"vpon\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"vse\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"wailing\"\t[\"chesterton-thursday.txt\"]\n",
      "\"walke\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"walt\"\t[\"whitman-leaves.txt\"]\n",
      "\"water\"\t[\"blake-poems.txt\"]\n",
      "\"waters\"\t[\"bible-kjv.txt\"]\n",
      "\"waves\"\t[\"whitman-leaves.txt\"]\n",
      "\"weather\"\t[\"chesterton-thursday.txt\"]\n",
      "\"went\"\t[\"chesterton-thursday.txt\"]\n",
      "\"wept\"\t[\"blake-poems.txt\"]\n",
      "\"wheel\"\t[\"edgeworth-parents.txt\"]\n",
      "\"whistler\"\t[\"chesterton-thursday.txt\"]\n",
      "\"white\"\t[\"chesterton-thursday.txt\", \"chesterton-ball.txt\"]\n",
      "\"whitman\"\t[\"whitman-leaves.txt\"]\n",
      "\"whose\"\t[\"milton-paradise.txt\"]\n",
      "\"widow\"\t[\"edgeworth-parents.txt\"]\n",
      "\"wild\"\t[\"blake-poems.txt\"]\n",
      "\"william\"\t[\"shakespeare-caesar.txt\", \"blake-poems.txt\"]\n",
      "\"winds\"\t[\"whitman-leaves.txt\"]\n",
      "\"woe\"\t[\"milton-paradise.txt\"]\n",
      "\"woman\"\t[\"austen-emma.txt\"]\n",
      "\"woodhouse\"\t[\"austen-emma.txt\"]\n",
      "\"word\"\t[\"whitman-leaves.txt\"]\n",
      "\"work\"\t[\"edgeworth-parents.txt\"]\n",
      "\"workman\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"world\"\t[\"melville-moby_dick.txt\", \"austen-emma.txt\", \"milton-paradise.txt\", \"chesterton-thursday.txt\"]\n",
      "\"write\"\t[\"whitman-leaves.txt\", \"blake-poems.txt\"]\n",
      "\"wrote\"\t[\"blake-poems.txt\"]\n",
      "\"yea\"\t[\"chesterton-thursday.txt\"]\n",
      "\"years\"\t[\"austen-emma.txt\"]\n",
      "\"young\"\t[\"chesterton-thursday.txt\"]\n",
      "\"youngest\"\t[\"austen-emma.txt\"]\n",
      "\"able\"\t[\"edgeworth-parents.txt\"]\n",
      "\"accounted\"\t[\"edgeworth-parents.txt\"]\n",
      "\"actus\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"admired\"\t[\"chesterton-thursday.txt\"]\n",
      "\"adventurous\"\t[\"milton-paradise.txt\"]\n",
      "\"affection\"\t[\"austen-emma.txt\"]\n",
      "\"affectionate\"\t[\"austen-emma.txt\"]\n",
      "\"ago\"\t[\"austen-emma.txt\"]\n",
      "\"aid\"\t[\"milton-paradise.txt\"]\n",
      "\"aimless\"\t[\"chesterton-thursday.txt\"]\n",
      "\"air\"\t[\"chesterton-ball.txt\"]\n",
      "\"also\"\t[\"chesterton-ball.txt\"]\n",
      "\"announced\"\t[\"chesterton-thursday.txt\"]\n",
      "\"answer\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"antic\"\t[\"chesterton-thursday.txt\"]\n",
      "\"aonian\"\t[\"milton-paradise.txt\"]\n",
      "\"apparrell\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"apron\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"arrow\"\t[\"chesterton-ball.txt\"]\n",
      "\"art\"\t[\"chesterton-thursday.txt\", \"shakespeare-caesar.txt\"]\n",
      "\"assistant\"\t[\"edgeworth-parents.txt\"]\n",
      "\"austen\"\t[\"austen-emma.txt\"]\n",
      "\"bad\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"ball\"\t[\"chesterton-ball.txt\"]\n",
      "\"beginning\"\t[\"bible-kjv.txt\", \"milton-paradise.txt\"]\n",
      "\"bentley\"\t[\"chesterton-thursday.txt\"]\n",
      "\"best\"\t[\"edgeworth-parents.txt\", \"shakespeare-caesar.txt\", \"austen-emma.txt\"]\n",
      "\"bible\"\t[\"bible-kjv.txt\"]\n",
      "\"blake\"\t[\"blake-poems.txt\"]\n",
      "\"bleak\"\t[\"chesterton-ball.txt\"]\n",
      "\"blessings\"\t[\"austen-emma.txt\"]\n",
      "\"blissful\"\t[\"milton-paradise.txt\"]\n",
      "\"blue\"\t[\"chesterton-ball.txt\"]\n",
      "\"body\"\t[\"melville-moby_dick.txt\", \"whitman-leaves.txt\"]\n",
      "\"book\"\t[\"bible-kjv.txt\", \"blake-poems.txt\", \"milton-paradise.txt\", \"whitman-leaves.txt\"]\n",
      "\"boys\"\t[\"chesterton-thursday.txt\"]\n",
      "\"brain\"\t[\"melville-moby_dick.txt\"]\n",
      "\"brook\"\t[\"milton-paradise.txt\"]\n",
      "\"brought\"\t[\"milton-paradise.txt\"]\n",
      "\"cabin\"\t[\"edgeworth-parents.txt\"]\n",
      "\"caesar\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"called\"\t[\"bible-kjv.txt\"]\n",
      "\"came\"\t[\"chesterton-thursday.txt\"]\n",
      "\"car\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"caresses\"\t[\"austen-emma.txt\"]\n",
      "\"carpenter\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"castle\"\t[\"edgeworth-parents.txt\"]\n",
      "\"certaine\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"chants\"\t[\"whitman-leaves.txt\"]\n",
      "\"chaos\"\t[\"milton-paradise.txt\"]\n",
      "\"chapter\"\t[\"austen-emma.txt\"]\n",
      "\"cheer\"\t[\"blake-poems.txt\"]\n",
      "\"chesterton\"\t[\"chesterton-thursday.txt\", \"chesterton-ball.txt\"]\n",
      "\"child\"\t[\"blake-poems.txt\"]\n",
      "\"children\"\t[\"edgeworth-parents.txt\"]\n",
      "\"chosen\"\t[\"milton-paradise.txt\"]\n",
      "\"clear\"\t[\"blake-poems.txt\"]\n",
      "\"clerihew\"\t[\"chesterton-thursday.txt\"]\n",
      "\"clever\"\t[\"austen-emma.txt\"]\n",
      "\"cloud\"\t[\"chesterton-thursday.txt\", \"blake-poems.txt\"]\n",
      "\"coat\"\t[\"melville-moby_dick.txt\"]\n",
      "\"cob\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"cobl\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"cobler\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"come\"\t[\"whitman-leaves.txt\"]\n",
      "\"comfortable\"\t[\"austen-emma.txt\"]\n",
      "\"commoners\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"conscience\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"consequence\"\t[\"austen-emma.txt\"]\n",
      "\"consumptive\"\t[\"melville-moby_dick.txt\"]\n",
      "\"created\"\t[\"bible-kjv.txt\"]\n",
      "\"creatures\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"crippled\"\t[\"chesterton-thursday.txt\"]\n",
      "\"cross\"\t[\"chesterton-ball.txt\"]\n",
      "\"d\"\t[\"blake-poems.txt\", \"whitman-leaves.txt\"]\n",
      "\"darkness\"\t[\"bible-kjv.txt\"]\n",
      "\"daughter\"\t[\"edgeworth-parents.txt\"]\n",
      "\"daughters\"\t[\"austen-emma.txt\"]\n",
      "\"day\"\t[\"bible-kjv.txt\", \"shakespeare-caesar.txt\"]\n",
      "\"death\"\t[\"chesterton-thursday.txt\", \"milton-paradise.txt\"]\n",
      "\"decay\"\t[\"chesterton-thursday.txt\"]\n",
      "\"deep\"\t[\"bible-kjv.txt\"]\n",
      "\"delight\"\t[\"milton-paradise.txt\"]\n",
      "\"democratic\"\t[\"whitman-leaves.txt\"]\n",
      "\"dick\"\t[\"melville-moby_dick.txt\"]\n",
      "\"didst\"\t[\"milton-paradise.txt\"]\n",
      "\"died\"\t[\"austen-emma.txt\"]\n",
      "\"directly\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"discussion\"\t[\"chesterton-ball.txt\"]\n",
      "\"disobedience\"\t[\"milton-paradise.txt\"]\n",
      "\"disposition\"\t[\"austen-emma.txt\"]\n",
      "\"distress\"\t[\"austen-emma.txt\"]\n",
      "\"divided\"\t[\"bible-kjv.txt\"]\n",
      "\"dost\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"drone\"\t[\"chesterton-thursday.txt\"]\n",
      "\"drop\"\t[\"blake-poems.txt\"]\n",
      "\"dust\"\t[\"melville-moby_dick.txt\"]\n",
      "\"dusting\"\t[\"melville-moby_dick.txt\"]\n",
      "\"early\"\t[\"austen-emma.txt\"]\n",
      "\"earth\"\t[\"bible-kjv.txt\", \"milton-paradise.txt\", \"chesterton-ball.txt\", \"whitman-leaves.txt\"]\n",
      "\"eden\"\t[\"milton-paradise.txt\"]\n",
      "\"edgeworth\"\t[\"edgeworth-parents.txt\"]\n",
      "\"edmund\"\t[\"chesterton-thursday.txt\"]\n",
      "\"eldest\"\t[\"edgeworth-parents.txt\"]\n",
      "\"embellished\"\t[\"melville-moby_dick.txt\"]\n",
      "\"emma\"\t[\"austen-emma.txt\"]\n",
      "\"emptiness\"\t[\"chesterton-ball.txt\"]\n",
      "\"en\"\t[\"whitman-leaves.txt\"]\n",
      "\"ended\"\t[\"chesterton-thursday.txt\"]\n",
      "\"enter\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"etymology\"\t[\"melville-moby_dick.txt\"]\n",
      "\"evening\"\t[\"chesterton-ball.txt\", \"bible-kjv.txt\"]\n",
      "\"every\"\t[\"blake-poems.txt\"]\n",
      "\"everything\"\t[\"chesterton-ball.txt\"]\n",
      "\"excellent\"\t[\"austen-emma.txt\"]\n",
      "\"existence\"\t[\"austen-emma.txt\"]\n",
      "\"experience\"\t[\"blake-poems.txt\"]\n",
      "\"expression\"\t[\"chesterton-ball.txt\"]\n",
      "\"face\"\t[\"bible-kjv.txt\"]\n",
      "\"faded\"\t[\"chesterton-thursday.txt\"]\n",
      "\"fallen\"\t[\"austen-emma.txt\"]\n",
      "\"far\"\t[\"chesterton-ball.txt\"]\n",
      "\"fast\"\t[\"milton-paradise.txt\"]\n",
      "\"father\"\t[\"austen-emma.txt\"]\n",
      "\"fear\"\t[\"chesterton-thursday.txt\"]\n",
      "\"feather\"\t[\"chesterton-thursday.txt\"]\n",
      "\"fell\"\t[\"edgeworth-parents.txt\"]\n",
      "\"fine\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"first\"\t[\"milton-paradise.txt\", \"whitman-leaves.txt\", \"bible-kjv.txt\"]\n",
      "\"fla\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"flags\"\t[\"melville-moby_dick.txt\"]\n",
      "\"flauius\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"flight\"\t[\"milton-paradise.txt\"]\n",
      "\"flowed\"\t[\"milton-paradise.txt\"]\n",
      "\"fly\"\t[\"chesterton-thursday.txt\"]\n",
      "\"flying\"\t[\"chesterton-ball.txt\"]\n",
      "\"forbidden\"\t[\"milton-paradise.txt\"]\n",
      "\"form\"\t[\"bible-kjv.txt\"]\n",
      "\"four\"\t[\"edgeworth-parents.txt\"]\n",
      "\"fruit\"\t[\"milton-paradise.txt\"]\n",
      "\"g\"\t[\"chesterton-thursday.txt\", \"chesterton-ball.txt\"]\n",
      "\"gay\"\t[\"melville-moby_dick.txt\", \"chesterton-thursday.txt\"]\n",
      "\"genesis\"\t[\"bible-kjv.txt\"]\n",
      "\"get\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"give\"\t[\"edgeworth-parents.txt\"]\n",
      "\"gleaming\"\t[\"chesterton-ball.txt\"]\n",
      "\"glee\"\t[\"blake-poems.txt\"]\n",
      "\"gloom\"\t[\"chesterton-thursday.txt\"]\n",
      "\"god\"\t[\"milton-paradise.txt\", \"bible-kjv.txt\"]\n",
      "\"good\"\t[\"bible-kjv.txt\"]\n",
      "\"governess\"\t[\"austen-emma.txt\"]\n",
      "\"grammar\"\t[\"melville-moby_dick.txt\"]\n",
      "\"grammars\"\t[\"melville-moby_dick.txt\"]\n",
      "\"grass\"\t[\"whitman-leaves.txt\"]\n",
      "\"greater\"\t[\"milton-paradise.txt\"]\n",
      "\"group\"\t[\"whitman-leaves.txt\"]\n",
      "\"handkerchief\"\t[\"melville-moby_dick.txt\"]\n",
      "\"handsome\"\t[\"austen-emma.txt\"]\n",
      "\"happy\"\t[\"austen-emma.txt\", \"blake-poems.txt\"]\n",
      "\"hear\"\t[\"blake-poems.txt\"]\n",
      "\"heart\"\t[\"melville-moby_dick.txt\"]\n",
      "\"heaven\"\t[\"bible-kjv.txt\"]\n",
      "\"heavenly\"\t[\"milton-paradise.txt\"]\n",
      "\"heavens\"\t[\"milton-paradise.txt\"]\n",
      "\"hence\"\t[\"whitman-leaves.txt\", \"shakespeare-caesar.txt\"]\n",
      "\"herman\"\t[\"melville-moby_dick.txt\"]\n",
      "\"hill\"\t[\"milton-paradise.txt\"]\n",
      "\"holiday\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"hollow\"\t[\"blake-poems.txt\"]\n",
      "\"home\"\t[\"austen-emma.txt\", \"shakespeare-caesar.txt\"]\n",
      "\"hope\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"house\"\t[\"austen-emma.txt\"]\n",
      "\"idle\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"ill\"\t[\"edgeworth-parents.txt\"]\n",
      "\"indeed\"\t[\"chesterton-thursday.txt\", \"shakespeare-caesar.txt\"]\n",
      "\"indistinct\"\t[\"austen-emma.txt\"]\n",
      "\"indulgent\"\t[\"austen-emma.txt\"]\n",
      "\"industrious\"\t[\"edgeworth-parents.txt\"]\n",
      "\"innocence\"\t[\"blake-poems.txt\"]\n",
      "\"inscriptions\"\t[\"whitman-leaves.txt\"]\n",
      "\"inspire\"\t[\"milton-paradise.txt\"]\n",
      "\"intends\"\t[\"milton-paradise.txt\"]\n",
      "\"introduction\"\t[\"blake-poems.txt\"]\n",
      "\"invented\"\t[\"chesterton-ball.txt\"]\n",
      "\"invoke\"\t[\"milton-paradise.txt\"]\n",
      "\"ireland\"\t[\"edgeworth-parents.txt\"]\n",
      "\"james\"\t[\"bible-kjv.txt\"]\n",
      "\"jane\"\t[\"austen-emma.txt\"]\n",
      "\"john\"\t[\"milton-paradise.txt\"]\n",
      "\"joy\"\t[\"blake-poems.txt\"]\n",
      "\"julius\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"k\"\t[\"chesterton-thursday.txt\", \"chesterton-ball.txt\"]\n",
      "\"keep\"\t[\"whitman-leaves.txt\"]\n",
      "\"king\"\t[\"bible-kjv.txt\"]\n",
      "\"know\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"known\"\t[\"melville-moby_dick.txt\"]\n",
      "\"labouring\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"lamb\"\t[\"blake-poems.txt\"]\n",
      "\"last\"\t[\"edgeworth-parents.txt\"]\n",
      "\"late\"\t[\"melville-moby_dick.txt\"]\n",
      "\"laughing\"\t[\"blake-poems.txt\"]\n",
      "\"laughter\"\t[\"chesterton-thursday.txt\"]\n",
      "\"leather\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"leaves\"\t[\"whitman-leaves.txt\"]\n",
      "\"lexicons\"\t[\"melville-moby_dick.txt\"]\n",
      "\"life\"\t[\"chesterton-thursday.txt\"]\n",
      "\"light\"\t[\"bible-kjv.txt\"]\n",
      "\"lit\"\t[\"chesterton-thursday.txt\"]\n",
      "\"little\"\t[\"austen-emma.txt\"]\n",
      "\"lived\"\t[\"edgeworth-parents.txt\", \"austen-emma.txt\"]\n",
      "\"lock\"\t[\"chesterton-thursday.txt\"]\n",
      "\"long\"\t[\"edgeworth-parents.txt\", \"austen-emma.txt\", \"whitman-leaves.txt\"]\n",
      "\"loss\"\t[\"milton-paradise.txt\"]\n",
      "\"lost\"\t[\"milton-paradise.txt\", \"chesterton-thursday.txt\"]\n",
      "\"loved\"\t[\"melville-moby_dick.txt\"]\n",
      "\"lucifer\"\t[\"chesterton-ball.txt\"]\n",
      "\"lust\"\t[\"chesterton-thursday.txt\"]\n",
      "\"machine\"\t[\"chesterton-ball.txt\"]\n",
      "\"made\"\t[\"blake-poems.txt\"]\n",
      "\"man\"\t[\"chesterton-thursday.txt\", \"milton-paradise.txt\"]\n",
      "\"maria\"\t[\"edgeworth-parents.txt\"]\n",
      "\"marriage\"\t[\"austen-emma.txt\"]\n",
      "\"mary\"\t[\"edgeworth-parents.txt\"]\n",
      "\"masse\"\t[\"whitman-leaves.txt\"]\n",
      "\"mates\"\t[\"whitman-leaves.txt\"]\n",
      "\"mechanicall\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"melville\"\t[\"melville-moby_dick.txt\"]\n",
      "\"men\"\t[\"chesterton-thursday.txt\", \"chesterton-ball.txt\"]\n",
      "\"mender\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"merry\"\t[\"blake-poems.txt\"]\n",
      "\"middle\"\t[\"milton-paradise.txt\"]\n",
      "\"mildly\"\t[\"melville-moby_dick.txt\"]\n",
      "\"milton\"\t[\"milton-paradise.txt\"]\n",
      "\"mind\"\t[\"chesterton-thursday.txt\"]\n",
      "\"mistress\"\t[\"austen-emma.txt\"]\n",
      "\"moby\"\t[\"melville-moby_dick.txt\"]\n",
      "\"mockingly\"\t[\"melville-moby_dick.txt\"]\n",
      "\"morning\"\t[\"bible-kjv.txt\"]\n",
      "\"mortal\"\t[\"milton-paradise.txt\"]\n",
      "\"mortality\"\t[\"melville-moby_dick.txt\"]\n",
      "\"moses\"\t[\"bible-kjv.txt\"]\n",
      "\"mother\"\t[\"austen-emma.txt\"]\n",
      "\"mount\"\t[\"milton-paradise.txt\"]\n",
      "\"moved\"\t[\"bible-kjv.txt\"]\n",
      "\"mur\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"murellus\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"muse\"\t[\"milton-paradise.txt\"]\n",
      "\"name\"\t[\"whitman-leaves.txt\"]\n",
      "\"nations\"\t[\"melville-moby_dick.txt\"]\n",
      "\"near\"\t[\"edgeworth-parents.txt\"]\n",
      "\"nearly\"\t[\"austen-emma.txt\", \"chesterton-ball.txt\"]\n",
      "\"night\"\t[\"bible-kjv.txt\"]\n",
      "\"nonentity\"\t[\"chesterton-thursday.txt\"]\n",
      "\"obliged\"\t[\"edgeworth-parents.txt\"]\n",
      "\"old\"\t[\"chesterton-thursday.txt\", \"melville-moby_dick.txt\", \"bible-kjv.txt\"]\n",
      "\"one\"\t[\"austen-emma.txt\", \"milton-paradise.txt\", \"whitman-leaves.txt\"]\n",
      "\"oracle\"\t[\"milton-paradise.txt\"]\n",
      "\"order\"\t[\"chesterton-thursday.txt\"]\n",
      "\"oreb\"\t[\"milton-paradise.txt\"]\n",
      "\"orphans\"\t[\"edgeworth-parents.txt\"]\n",
      "\"ouer\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"ought\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"overworked\"\t[\"edgeworth-parents.txt\"]\n",
      "\"owning\"\t[\"whitman-leaves.txt\"]\n",
      "\"pale\"\t[\"melville-moby_dick.txt\"]\n",
      "\"paradise\"\t[\"milton-paradise.txt\"]\n",
      "\"parent\"\t[\"edgeworth-parents.txt\"]\n",
      "\"parish\"\t[\"edgeworth-parents.txt\"]\n",
      "\"pen\"\t[\"blake-poems.txt\"]\n",
      "\"period\"\t[\"austen-emma.txt\"]\n",
      "\"person\"\t[\"whitman-leaves.txt\"]\n",
      "\"pipe\"\t[\"blake-poems.txt\"]\n",
      "\"piped\"\t[\"blake-poems.txt\"]\n",
      "\"piper\"\t[\"blake-poems.txt\"]\n",
      "\"piping\"\t[\"blake-poems.txt\"]\n",
      "\"place\"\t[\"austen-emma.txt\"]\n",
      "\"pleas\"\t[\"whitman-leaves.txt\"]\n",
      "\"pleasant\"\t[\"blake-poems.txt\"]\n",
      "\"pluck\"\t[\"blake-poems.txt\"]\n",
      "\"plume\"\t[\"chesterton-thursday.txt\"]\n",
      "\"poems\"\t[\"blake-poems.txt\"]\n",
      "\"prima\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"primus\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"profession\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"professor\"\t[\"chesterton-ball.txt\"]\n",
      "\"prose\"\t[\"milton-paradise.txt\"]\n",
      "\"proudly\"\t[\"chesterton-thursday.txt\"]\n",
      "\"pursues\"\t[\"milton-paradise.txt\"]\n",
      "\"queer\"\t[\"melville-moby_dick.txt\"]\n",
      "\"read\"\t[\"blake-poems.txt\"]\n",
      "\"reed\"\t[\"blake-poems.txt\"]\n",
      "\"regain\"\t[\"milton-paradise.txt\"]\n",
      "\"remembrance\"\t[\"austen-emma.txt\"]\n",
      "\"reminded\"\t[\"melville-moby_dick.txt\"]\n",
      "\"respect\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"restore\"\t[\"milton-paradise.txt\"]\n",
      "\"resuming\"\t[\"whitman-leaves.txt\"]\n",
      "\"return\"\t[\"whitman-leaves.txt\"]\n",
      "\"rhyme\"\t[\"milton-paradise.txt\"]\n",
      "\"rich\"\t[\"austen-emma.txt\"]\n",
      "\"rose\"\t[\"milton-paradise.txt\"]\n",
      "\"rossmore\"\t[\"edgeworth-parents.txt\"]\n",
      "\"round\"\t[\"chesterton-thursday.txt\"]\n",
      "\"ruins\"\t[\"edgeworth-parents.txt\"]\n",
      "\"rule\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"rural\"\t[\"blake-poems.txt\"]\n",
      "\"safe\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"said\"\t[\"whitman-leaves.txt\", \"blake-poems.txt\", \"bible-kjv.txt\"]\n",
      "\"sang\"\t[\"chesterton-ball.txt\", \"blake-poems.txt\"]\n",
      "\"saw\"\t[\"blake-poems.txt\", \"bible-kjv.txt\"]\n",
      "\"say\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"school\"\t[\"melville-moby_dick.txt\"]\n",
      "\"science\"\t[\"chesterton-thursday.txt\"]\n",
      "\"scoena\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"seat\"\t[\"milton-paradise.txt\"]\n",
      "\"secret\"\t[\"milton-paradise.txt\"]\n",
      "\"see\"\t[\"melville-moby_dick.txt\"]\n",
      "\"seed\"\t[\"milton-paradise.txt\"]\n",
      "\"seemed\"\t[\"austen-emma.txt\", \"chesterton-ball.txt\"]\n",
      "\"self\"\t[\"whitman-leaves.txt\"]\n",
      "\"separate\"\t[\"whitman-leaves.txt\"]\n",
      "\"set\"\t[\"whitman-leaves.txt\"]\n",
      "\"shakespeare\"\t[\"shakespeare-caesar.txt\"]\n",
      "\"shame\"\t[\"chesterton-thursday.txt\"]\n",
      "\"shepherd\"\t[\"milton-paradise.txt\"]\n",
      "\"ship\"\t[\"chesterton-ball.txt\"]\n",
      "\"short\"\t[\"austen-emma.txt\"]\n",
      "\"showed\"\t[\"chesterton-thursday.txt\"]\n",
      "\"sick\"\t[\"chesterton-thursday.txt\"]\n",
      "\"sight\"\t[\"blake-poems.txt\"]\n",
      "\"signe\"\t[\"shakespeare-caesar.txt\"]\n",
      "Removing temp directory /tmp/inverted_index.root.20210110.080310.691190...\n"
     ]
    }
   ],
   "source": [
    "!python inverted_index.py -r local books.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcRwm-8Bq_gw"
   },
   "source": [
    "## Exercise 4 -- Matrix multiplication\n",
    "\n",
    "We have two matrices $A$ ($n$ rows and $m$ columns) \n",
    "and $B$ ($m$ rows and $p$ columns). \n",
    "The two matrices are stored in a text file; each line contains: \n",
    "\n",
    "* the identifier of the matrix.\n",
    "* a row index.\n",
    "* the values of a row in the matrix.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Execute the following cell to create the file matrices.txt**\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 545,
     "status": "ok",
     "timestamp": 1610266560244,
     "user": {
      "displayName": "MARCO ANTONIO FARFAN QUIROZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyouCic8PRJa_OhiXqrKl9D6yotjSxiwR5iKw9=s64",
      "userId": "01920866730777537430"
     },
     "user_tz": -60
    },
    "id": "d_uYZ0ZlraeL",
    "outputId": "dfbeeab0-8da4-4290-ded8-b5ea3226ae44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing matrices.txt\n"
     ]
    }
   ],
   "source": [
    "%%file matrices.txt\n",
    "A,0,1,2,4\n",
    "A,1,2,3,5\n",
    "A,2,4,3,2\n",
    "B,0,4,2,2,5\n",
    "B,1,1,3,3,2\n",
    "B,2,4,4,0,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaPTXHHctwBJ"
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "**Write a MapReduce job to multiply matrices.**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "**Hint.** We need two iterations of MapReduce. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1610271531283,
     "user": {
      "displayName": "MARCO ANTONIO FARFAN QUIROZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyouCic8PRJa_OhiXqrKl9D6yotjSxiwR5iKw9=s64",
      "userId": "01920866730777537430"
     },
     "user_tz": -60
    },
    "id": "Tg8Obq0GtidL",
    "outputId": "0d6522ed-1edf-4545-952a-210b2043b342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing matrix_multiplication.py\n"
     ]
    }
   ],
   "source": [
    "%%file matrix_multiplication.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MatrixMultiplication(MRJob):\n",
    "    def first_mapper(self, _, line):\n",
    "    items = line.split(\",\")\n",
    "    matrix = items[0]\n",
    "    row = int(items[1])\n",
    "    values = items[2:]\n",
    "    col = 0\n",
    "    for v in values:\n",
    "        if matrix == \"A\":\n",
    "            yield(col, (\"A\", row, int(v)))\n",
    "        else:\n",
    "            yield(row, (\"B\", col, int(v)))\n",
    "        col += 1\n",
    "\n",
    "    def first_reducer(self, j, values):\n",
    "        Avalues = []\n",
    "        Bvalues = []\n",
    "        for (matrix, coord, value) in values:\n",
    "            if matrix == \"A\":\n",
    "                Avalues.append((coord, value))\n",
    "            else: \n",
    "                Bvalues.append((coord, value))\n",
    "        for (i, aij) in Avalues:\n",
    "            for (k, bjk) in Bvalues:\n",
    "                yield((i, k), aij*bjk)\n",
    "\n",
    "    def second_reducer(self, coords, values):\n",
    "        yield(coords, sum(values))\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "          MRStep(mapper=self.first_mapper,\n",
    "                  reducer=self.first_reducer),\n",
    "          MRStep(reducer=self.second_reducer)\n",
    "        ]\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MatrixMultiplication.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4-UZAfRWipV"
   },
   "source": [
    "---\n",
    "**Execute the following cell to test your implementation.**\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3333,
     "status": "ok",
     "timestamp": 1610271535816,
     "user": {
      "displayName": "MARCO ANTONIO FARFAN QUIROZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyouCic8PRJa_OhiXqrKl9D6yotjSxiwR5iKw9=s64",
      "userId": "01920866730777537430"
     },
     "user_tz": -60
    },
    "id": "FYImIsNPtnzJ",
    "outputId": "819bd72f-43a1-43f6-b38f-87f59859271f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for local runner\n",
      "Creating temp directory /tmp/matrix_multiplication.root.20210110.093852.918404\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "job output is in /tmp/matrix_multiplication.root.20210110.093852.918404/output\n",
      "Streaming final output from /tmp/matrix_multiplication.root.20210110.093852.918404/output...\n",
      "[2, 1]\t25\n",
      "[2, 2]\t17\n",
      "[2, 3]\t32\n",
      "[0, 0]\t22\n",
      "[0, 1]\t24\n",
      "[0, 2]\t8\n",
      "[0, 3]\t21\n",
      "[1, 0]\t31\n",
      "[1, 1]\t33\n",
      "[1, 2]\t13\n",
      "[1, 3]\t31\n",
      "[2, 0]\t27\n",
      "Removing temp directory /tmp/matrix_multiplication.root.20210110.093852.918404...\n"
     ]
    }
   ],
   "source": [
    "!python matrix_multiplication.py -r local matrices.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKFTjlNCGB90"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of big-data-ia-tutorial2-solution.ipynb",
   "provenance": [
    {
     "file_id": "1W8kyQmEpxiwoP66WG6ZQtNRfQwQQVqSI",
     "timestamp": 1610264848233
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
