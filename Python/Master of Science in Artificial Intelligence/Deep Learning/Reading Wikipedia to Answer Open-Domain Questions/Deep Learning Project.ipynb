{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Project - DrQA\n",
    "\n",
    "Reproducibility challenge, we will try to reproduce the methods, models\n",
    "and results put forward by the following paper:\n",
    "\n",
    "Danqi Chen, Adam Fisch, Jason Weston and Antoine Bordes. 2017. Reading Wikipedia to Answer Open-Domain Questions. arXiv preprint : 1704.00051\n",
    "\n",
    "The paper considers the problem of answering factoid questions in an open-domain setting using Wikipedia as the unique knowledge source, such as one does when looking for answers in an encyclopedia. Unlike knowledge bases , which are easier for computers to process but too sparsely populated for open-domain question answering (Miller et al., 2016), Wikipedia contains up-to-date knowledge that humans are interested in. It is designed, however, for humans - not machines - to read. Using Wikipedia articles as the knowledge source causes the task of question answering to combine the challenges of both large-scale open-domain question answering and of machine comprehension of text. The approach of the paper's authors is generic and could be switched to other collections of documents, books, or even daily updated newspapers. In contrast to large-scale question answering systems that rely on multiple sources to answer by pairing KBs, dictionaries, and even news articles, books, etc, thus relying on information redundancy among the sources to answer correctly. Having a single knowledge source forces the model to be very precise while searching for an answer as the evidence might appear only once. The model developed by the paper DrQA is a strong system for question answering from Wikipedia composed of: (1) Document Retriever, a module using bigram hashing and TF-IDF matching designed to, given a question, efficiently return a subset of relevant articles and (2) Document Reader, a multi-layer recurrent neural network machine comprehension model trained to detect answer spans in those few returned documents.\n",
    "\n",
    "In the reproduction of the paper will focus mostly on the document reader part, since the document retriever part of the system, though interesting and thought prokoving, is not relevant to the taught course material (We will, either, use the authors implementation or a standard search API depending on the dataset, but, if the time allows it, we will try implementing it since we deem that retrieving and feeding information to the network is an integral part of deep learning ).\n",
    "\n",
    "We will start project by implementing the document reader part of the system and train it on the SQuAD (Rajpurkar et al., 2016) dataset, we can then test it on the different open question answering datasets used fo benchmarking text comprehension systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGycXd1webTg"
   },
   "source": [
    "**DrQA Implementation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liEnsYqXTvY3"
   },
   "outputs": [],
   "source": [
    "!bash download.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ckQ2Xp9MFqy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, os, string, typing, gc, json, unicodedata, time\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import torchtext\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "nlp = spacy.load('en')\n",
    "from utilis import *\n",
    "from model import *\n",
    "from SquadDS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGzPMk0aKz9o"
   },
   "outputs": [],
   "source": [
    "# load SQuAD dataset json files\n",
    "\n",
    "train_data = load_json('./SQuAD/train-v1.1.json')\n",
    "valid_data = load_json('./SQuAD/dev-v1.1.json')\n",
    "\n",
    "# parse the json structure to return the data as a list of dictionaries\n",
    "\n",
    "train_list = parse_data(train_data)\n",
    "valid_list = parse_data(valid_data)\n",
    "\n",
    "# converting the lists into dataframes\n",
    "\n",
    "train_df = pd.DataFrame(train_list)\n",
    "valid_df = pd.DataFrame(valid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exe9WlfBKz9p"
   },
   "outputs": [],
   "source": [
    "train_df.context = train_df.context.apply(normalize_spaces)\n",
    "valid_df.context = valid_df.context.apply(normalize_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNjZL4HQKz9r"
   },
   "outputs": [],
   "source": [
    "vocab_text = gather_text_for_vocab([train_df, valid_df])\n",
    "\n",
    "word2idx, idx2word, word_vocab = build_word_vocab(vocab_text)\n",
    "\n",
    "train_df['context_ids'] = train_df.context.apply(context_to_ids, word2idx=word2idx)\n",
    "valid_df['context_ids'] = valid_df.context.apply(context_to_ids, word2idx=word2idx)\n",
    "\n",
    "train_df['question_ids'] = train_df.question.apply(question_to_ids,  word2idx=word2idx)\n",
    "valid_df['question_ids'] = valid_df.question.apply(question_to_ids,  word2idx=word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qHAn7cVKz9u"
   },
   "outputs": [],
   "source": [
    "# get indices with tokenization errors and drop those indices \n",
    "\n",
    "train_err = get_error_indices(train_df, idx2word)\n",
    "valid_err = get_error_indices(valid_df, idx2word)\n",
    "\n",
    "train_df.drop(train_err, inplace=True)\n",
    "valid_df.drop(valid_err, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jonrWHiKz9v"
   },
   "outputs": [],
   "source": [
    "# get start and end positions of answers from the context\n",
    "# this is basically the label for training QA models\n",
    "\n",
    "train_label_idx = train_df.apply(index_answer, axis=1, idx2word=idx2word)\n",
    "valid_label_idx = valid_df.apply(index_answer, axis=1, idx2word=idx2word)\n",
    "\n",
    "train_df['label_idx'] = train_label_idx\n",
    "valid_df['label_idx'] = valid_label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZLY6Zn5Kz9x"
   },
   "outputs": [],
   "source": [
    "train_dataset = SquadDataset(train_df, 32)\n",
    "valid_dataset = SquadDataset(valid_df, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Mgsjz3dKz9z"
   },
   "outputs": [],
   "source": [
    "glove_dict = create_glove_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wa0bO2tKz90"
   },
   "outputs": [],
   "source": [
    "weights_matrix, words_found = create_word_embedding(glove_dict, word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85EPwSpVKz94"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "HIDDEN_DIM = 128\n",
    "EMB_DIM = 300\n",
    "NUM_LAYERS = 3\n",
    "NUM_DIRECTIONS = 2\n",
    "DROPOUT = 0.3\n",
    "device = torch.device('cuda')\n",
    "\n",
    "model = DocumentReader(HIDDEN_DIM,\n",
    "                       EMB_DIM, \n",
    "                       NUM_LAYERS, \n",
    "                       NUM_DIRECTIONS, \n",
    "                       DROPOUT, \n",
    "                       device, glove_dict, word_vocab).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-7lUxV0Kz94"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adamax(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3lmH5uSKz96",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "ems = []\n",
    "f1s = []\n",
    "epochs = 40\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_dataset, device, optimizer)\n",
    "    valid_loss, em, f1 = valid(model, valid_dataset, device, idx2word)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    ems.append(em)\n",
    "    f1s.append(f1)\n",
    "    \n",
    "    print(f\"Epoch train loss : {train_loss}| Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"Epoch valid loss: {valid_loss}\")\n",
    "    print(f\"Epoch EM: {em}\")\n",
    "    print(f\"Epoch F1: {f1}\")\n",
    "    print(\"====================================================================================\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "1. DrQA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
